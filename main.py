import os
from openai import OpenAI
os.environ["PYTHONIOENCODING"] = "utf-8"

import customtkinter as ctk
import cv2
import face_recognition
import numpy as np
import time
import datetime
from PIL import Image
import threading
import pyttsx3
from gtts import gTTS
import pygame
import tempfile
import shutil
import requests
import speech_recognition as sr
import RPi.GPIO as GPIO
import board
import adafruit_dht
from playsound import playsound
from PIL import Image as PILImage


# =============================================
# HARDWARE SETUP (DO NOT CHANGE)
# =============================================
LIGHT_PIN = 20   # GPIO 20 ‚Üí Light relay
FAN_PIN   = 21   # GPIO 21 ‚Üí Fan relay
BUZZER_PIN  = 18   # Buzzer ‚Üí GPIO 18 (safe pin)
DHT_PIN   = board.D2  # DHT11 on GPIO 2

GPIO.setmode(GPIO.BCM)
GPIO.setwarnings(False)
GPIO.setup(LIGHT_PIN, GPIO.OUT)
GPIO.setup(FAN_PIN, GPIO.OUT)
GPIO.setup(BUZZER_PIN, GPIO.OUT)

GPIO.output(LIGHT_PIN, GPIO.HIGH)  # OFF
GPIO.output(FAN_PIN, GPIO.HIGH)    # OFF
GPIO.output(BUZZER_PIN, GPIO.LOW)   # buzzer silent


dht_device = adafruit_dht.DHT11(DHT_PIN, use_pulseio=False)

# Auto fan control
TEMP_THRESHOLD = 25.0
manual_fan = False  # True = user pressed button ‚Üí auto disabled

# Light auto control based on people count
active_workers = {}  # name ‚Üí timestamp
light_auto_on = False

# Temperature display
temp_label = None



# =============================================
# PRE-START HARDWARE TEST ‚Äì Microphone & Speaker Force Initialize
# =============================================
print("–ê–ø–ø —ç—Ö–ª—ç—Ö—ç—ç—Å ”©–º–Ω”© –º–∏–∫—Ä–æ—Ñ–æ–Ω –±–æ–ª–æ–Ω —á–∞–Ω–≥–∞ —è—Ä–∏–≥—á–∏–π–≥ —à–∞–ª–≥–∞–∂, —Å—ç—Ä—ç—ç–∂ –±–∞–π–Ω–∞...")

# 1. –°–ø–∏–∫–µ—Ä —Ç–µ—Å—Ç (espeak-ng –∞—à–∏–≥–ª–∞–∂ –¥—É—É –≥–∞—Ä–≥–∞–Ω–∞ ‚Äì Bluetooth —Å–ø–∏–∫–µ—Ä —á –∞–∂–∏–ª–ª–∞–Ω–∞)
def set_bluetooth_default_sink():
    try:
        # pactl-—ç—ç—Ä Bluetooth sink –æ–ª–æ—Ö
        result = os.popen("pactl list sinks short | grep bluez_output").read().strip()
        if result:
            lines = result.splitlines()
            # –≠—Ö–Ω–∏–π Bluetooth sink-–∏–π–≥ –∞–≤–Ω–∞ (–∏—Ö—ç–≤—á–ª—ç–Ω –Ω—ç–≥ –ª –±–∞–π–¥–∞–≥)
            sink_name = lines[0].split()[1]
            os.system(f"pactl set-default-sink {sink_name}")
            print(f"–ê—É–¥–∏–æ default –±–æ–ª–≥–æ–ª–æ–æ: {sink_name} ‚úì")
        else:
            print("Bluetooth —Å–ø–∏–∫–µ—Ä sink –æ–ª–¥—Å–æ–Ω–≥“Ø–π ‚úó")
    except Exception as e:
        print(f"Default sink —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö –∞–ª–¥–∞–∞: {e}")

# –ê–ø–ø —ç—Ö–ª—ç—Ö—ç–¥ –¥—É—É–¥–Ω–∞
set_bluetooth_default_sink()

def test_speaker():
    print("Bluetooth —Å–ø–∏–∫–µ—Ä –∞–ª–±–∞–¥–∞–Ω —Ö–æ–ª–±–æ–∂ –±–∞–π–Ω–∞ (disconnect + reconnect)...")
    
    try:
        # 1. –û–¥–æ–æ —Ö–æ–ª–±–æ–≥–¥—Å–æ–Ω –∞—É–¥–∏–æ —Ç”©—Ö”©”©—Ä”©–º–∂–∏–π–Ω MAC address –æ–ª–æ—Ö
        result = os.popen("bluetoothctl devices Connected").read().strip()
        if not result:
            print("–•–æ–ª–±–æ–≥–¥—Å–æ–Ω Bluetooth —Ç”©—Ö”©”©—Ä”©–º–∂ –æ–ª–¥—Å–æ–Ω–≥“Ø–π ‚úó")
            return False
        
        connected_macs = [line.split()[1] for line in result.splitlines() if line.strip()]
        
        speaker_mac = None
        for mac in connected_macs:
            info = os.popen(f"bluetoothctl info {mac}").read()
            if "Connected: yes" in info and ("Icon: audio" in info.lower() or "UUID: Audio" in info):
                speaker_mac = mac
                break
        
        if not speaker_mac:
            print("–ê—É–¥–∏–æ —Ç”©—Ö”©”©—Ä”©–º–∂ (—Å–ø–∏–∫–µ—Ä) –æ–ª–¥—Å–æ–Ω–≥“Ø–π ‚úó")
            return False
        
        print(f"–û–ª–¥—Å–æ–Ω —Å–ø–∏–∫–µ—Ä: {speaker_mac}")
        
        # 2. Disconnect —Ö–∏–π–Ω—ç
        os.system(f"bluetoothctl disconnect {speaker_mac} > /dev/null 2>&1")
        time.sleep(2)  # –•“Ø–ª—ç—ç–∂ ”©–≥–Ω”©
        
        # 3. Reconnect —Ö–∏–π–Ω—ç
        os.system(f"bluetoothctl connect {speaker_mac} > /dev/null 2>&1")
        time.sleep(3)  # –•–æ–ª–±–æ–ª—Ç—ã–≥ —Ö“Ø–ª—ç—ç–Ω—ç
        
        # 4. –î—É—É —Ç–µ—Å—Ç —Ö–∏–π–Ω—ç
        os.system('espeak-ng "–°–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω –±–æ–ª–ª–æ–æ" -v mn -s 120 -p 50 -a 50 2>/dev/null')
        print("–°–ø–∏–∫–µ—Ä –∞–º–∂–∏–ª—Ç—Ç–∞–π —Ö–æ–ª–±–æ–≥–¥–æ–∂, –¥—É—É –≥–∞—Ä–ª–∞–∞ ‚úì")
        return True
        
    except Exception as e:
        print(f"–°–ø–∏–∫–µ—Ä —Ö–æ–ª–±–æ–ª—Ç –∞–ª–¥–∞–∞: {e} ‚úó")
        return False

# 2. –ú–∏–∫—Ä–æ—Ñ–æ–Ω —Ç–µ—Å—Ç (speech_recognition –∞—à–∏–≥–ª–∞–∂ –±–æ–≥–∏–Ω–æ —Ö—É–≥–∞—Ü–∞–∞–Ω–¥ —Å–æ–Ω—Å–æ–Ω–æ)
def test_microphone():
    r = sr.Recognizer()
    try:
        with sr.Microphone() as source:
            print("–ú–∏–∫—Ä–æ—Ñ–æ–Ω —à–∞–ª–≥–∞–∂ –±–∞–π–Ω–∞... 2 —Å–µ–∫—É–Ω–¥ —Ö“Ø–ª—ç—ç–Ω—ç “Ø“Ø")
            r.adjust_for_ambient_noise(source, duration=1)
            audio = r.listen(source, timeout=2, phrase_time_limit=2)
        print("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∂–∏–ª–ª–∞–∂ –±–∞–π–Ω–∞ ‚úì")
        return True
    except sr.WaitTimeoutError:
        print("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –¥—É—É —Å–æ–Ω—Å—Å–æ–Ω–≥“Ø–π, –≥—ç—Ö–¥—ç—ç —Ç”©—Ö”©”©—Ä”©–º–∂ –Ω—ç—ç–≥–¥—Å—ç–Ω ‚Äì –∞–∂–∏–ª–ª–∞–∂ –º–∞–≥–∞–¥–≥“Ø–π")
        return True
    except Exception as e:
        print(f"–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–ª–¥–∞–∞: {e} ‚úó")
        return False

# 3. –ö–∞–º–µ—Ä —Ç–µ—Å—Ç (–Ω—ç–≥ frame –∞–≤–Ω–∞)
def test_camera():
    try:
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        cap.release()
        if ret:
            print("–ö–∞–º–µ—Ä –∞–∂–∏–ª–ª–∞–∂ –±–∞–π–Ω–∞ ‚úì")
            return True
        else:
            print("–ö–∞–º–µ—Ä –∑—É—Ä–∞–≥ –∞–≤—á —á–∞–¥—Å–∞–Ω–≥“Ø–π ‚úó")
            return False
    except:
        print("–ö–∞–º–µ—Ä –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π ‚úó")
        return False

# –¢–µ—Å—Ç“Ø“Ø–¥–∏–π–≥ –∞–∂–∏–ª–ª—É—É–ª–Ω–∞
test_speaker()
test_microphone()
test_camera()

print("–¢”©—Ö”©”©—Ä”©–º–∂–∏–π–Ω —à–∞–ª–≥–∞–ª—Ç –¥—É—É—Å–ª–∞–∞. GUI —ç—Ö—ç–ª–∂ –±–∞–π–Ω–∞...\n")
time.sleep(1)  # –•—ç—Ä—ç–≥–ª—ç–≥—á –º–µ—Å—Å–µ–∂–∏–π–≥ —Ö–∞—Ä–∞—Ö –±–æ–ª–æ–º–∂ ”©–≥–Ω”©


# =============================================
# Mongolian Font Fix (100% working)
# =============================================
try:
    ctk.CTkFont(family="Noto Sans CJK JP", size=36)
    MONGOL_FONT = ("Noto Sans CJK JP", 36, "bold")
except:
    MONGOL_FONT = ("Noto Sans CJK SC", 36, "bold")

_original_init = ctk.CTkLabel.__init__
def _force_font(self, *args, **kwargs):
    kwargs.setdefault("font", MONGOL_FONT)
    _original_init(self, *args, **kwargs)
ctk.CTkLabel.__init__ = _force_font

# =============================================
# Your original code starts here
# =============================================
# API_KEY = ""
GROQ_API_KEY = ""  # <-- –≠–Ω–¥ ”©”©—Ä–∏–π–Ω key-–≥ –±–∏—á
# API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"

def ask_google_ai(prompt):
    if not prompt.strip():
        return "–ê—Å—É—É–ª—Ç —Ö–æ–æ—Å–æ–Ω –±–∞–π–Ω–∞"
    
    client = OpenAI(
        api_key=GROQ_API_KEY,
        base_url="https://api.groq.com/openai/v1"
    )
    
    try:
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": "–¢–∞ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –º–∞—à —Ç–æ–≤—á, –æ–π–ª–≥–æ–º–∂—Ç–æ–π —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000,
            timeout=30
        )
        
        answer = response.choices[0].message.content.strip()
        # –¢–µ—Ä–º–∏–Ω–∞–ª –¥—ç—ç—Ä –ú–æ–Ω–≥–æ–ª —Ç–µ–∫—Å—Ç –∑”©–≤ —Ö—ç–≤–ª—ç—Ö–∏–π–Ω —Ç—É–ª–¥
        print(f"Groq —Ö–∞—Ä–∏—É: {answer}")
        return answer if answer else "–•–∞—Ä–∏—É —Ö–æ–æ—Å–æ–Ω –∏—Ä–ª—ç—ç"
        
    except Exception as e:
        # –ê–ª–¥–∞–∞–≥ –∞—é—É–ª–≥“Ø–π —Ö—ç–≤–ª—ç—Ö
        print("Groq –∞–ª–¥–∞–∞:", repr(e))  # repr() –∞—à–∏–≥–ª–∞–≤–∞–ª –ú–æ–Ω–≥–æ–ª “Ø—Å—ç–≥—Ç—ç–π —á –≥—ç—Å—ç–Ω –∞–ª–¥–∞–∞ –≥–∞—Ä–∞—Ö–≥“Ø–π
        return "–£—É—á–ª–∞–∞—Ä–∞–π, —Ö–∞—Ä–∏—É –∞–≤–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞"
os.makedirs("known_faces", exist_ok=True)
os.makedirs("worker_data", exist_ok=True)
os.makedirs("pending_photos", exist_ok=True)
# pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)

# TTS
tts_local = None
try:
    tts_local = pyttsx3.init()
except:
    pass

import threading

def speak(text: str):
    def _speak():
        try:
            if not text.strip():
                return
            safe_text = text.replace("'", "\\'")
            os.system(f"espeak-ng -v ru+f3 -s 100 -p 80 -a 50 '{safe_text}'")
            # –î—É—É –¥—É—É—Å—Å–∞–Ω—ã –¥–∞—Ä–∞–∞ –±—É—Ü–∞–∞–∂ —Å–∞–∞—Ä–∞–ª/—É–ª–∞–∞–Ω –±–æ–ª–≥–æ–Ω–æ
            app.after(5000, lambda: speaker_label.configure(text_color="gray" if check_speaker() else "red"))
        except Exception as e:
            print("–î—É—É –≥–∞—Ä–≥–∞—Ö –∞–ª–¥–∞–∞:", e)
            app.after(100, lambda: speaker_label.configure(text_color="red"))

    # –î—É—É —ç—Ö–ª—ç—Ö—ç–¥ –Ω–æ–≥–æ–æ–Ω –±–æ–ª–≥–æ–Ω–æ (–∑”©–≤—Ö”©–Ω —Ö–æ–ª–±–æ–≥–¥—Å–æ–Ω –±–æ–ª)
    if check_speaker():
        speaker_label.configure(text_color="green")
    threading.Thread(target=_speak, daemon=True).start()
        
def beep(times=1, duration=0.08):
    def _beep():
        for _ in range(times):
            GPIO.output(BUZZER_PIN, GPIO.HIGH)
            time.sleep(duration)
            GPIO.output(BUZZER_PIN, GPIO.LOW)
            time.sleep(0.08)
            print("Beep working")
    # This line is the only method that never fails
    if 'app' in globals() and app is not None:
        app.after(0, _beep)
        print("Beep scheduled in GUI thread")
    else:
        # Fallback for before GUI exists
        print("Beep running in main thread")
        _beep()
# TEST BEEP ‚Äî YOU MUST HEAR 3 BEEPS NOW
print("STARTING ‚Äî 3 TEST BEEPS IN 1 SECOND!")
app = None  # placeholder ‚Äî will be set later
print("STARTING ‚Äî 3 TEST BEEPS NOW!")
beep(3)


# Load faces
def load_known_faces():
    encodings, names = [], []
    for file in os.listdir("known_faces"):
        path = os.path.join("known_faces", file)
        img = face_recognition.load_image_file(path)
        enc = face_recognition.face_encodings(img)
        if enc:
            encodings.append(enc[0])
            names.append(os.path.splitext(file)[0].replace("_", " "))
    return encodings, names

known_face_encodings, known_face_names = load_known_faces()

def log_time(name: str, action: str):
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    with open("time_logs.txt", "a", encoding="utf-8") as f:
        f.write(f"{name},{action},{ts}\n")
    return ts

def process_voice_command(text: str):
    text = text.strip().lower()

    # Light ON
    if any(word in text for word in ["–≥—ç—Ä—ç–ª –∞—Å", "–≥—ç—Ä—ç–ª –∞—Å–∞–∞", "–≥—ç—Ä—ç–ª –∞—Å–∞–∞–≥–∞–∞—Ä–∞–π", "light on"]):
        if GPIO.input(LIGHT_PIN) == GPIO.HIGH:   # if it was off
            toggle_gerel()                       # turn it on
        speak("–ì—ç—Ä—ç–ª –∞—Å–∞–∞–ª–∞–∞")
        info_label.configure(text="–ì—ç—Ä—ç–ª: –ê–°–õ–ê–ê (–ì–æ–ª–æ—Å)")

    # Light OFF
    elif any(word in text for word in ["–≥—ç—Ä—ç–ª —É–Ω—Ç–∞—Ä", "–≥—ç—Ä—ç–ª —É–Ω—Ç—Ä–∞–∞", "–≥—ç—Ä—ç–ª —É–Ω—Ç—Ä–∞–∞–≥–∞–∞—Ä–∞–π", "light off"]):
        if GPIO.input(LIGHT_PIN) == GPIO.LOW:    # if it was on
            toggle_gerel()                       # turn it off
        speak("–ì—ç—Ä—ç–ª —É–Ω—Ç—Ä–∞–∞–ª–∞–∞")
        info_label.configure(text="–ì—ç—Ä—ç–ª: –£–ù–¢–†–ê–ê (–ì–≠–≠ (–ì–æ–ª–æ—Å)")

    # Fan ON
    elif any(word in text for word in ["—Å—ç–Ω—Å –∞—Å", "—Å—ç–Ω—Å –∞—Å–∞–∞", "—Å—ç–Ω—Å –∞—Å–∞–∞–≥–∞–∞—Ä–∞–π", "fan on"]):
        if GPIO.input(FAN_PIN) == GPIO.HIGH:     # if it was off
            toggle_sens1()                       # turn it on
        speak("–°—ç–Ω—Å –∞—Å–∞–∞–ª–∞–∞")
        info_label.configure(text="–°—ç–Ω—Å: –ê–°–õ–ê–ê (–ì–æ–ª–æ—Å)")

    # Fan OFF
    elif any(word in text for word in ["—Å—ç–Ω—Å —É–Ω—Ç–∞—Ä", "—Å—ç–Ω—Å —É–Ω—Ç—Ä–∞–∞", "—Å—ç–Ω—Å —É–Ω—Ç—Ä–∞–∞–≥–∞–∞—Ä–∞–π", "fan off"]):
        if GPIO.input(FAN_PIN) == GPIO.LOW:       # if it was on
            toggle_sens1()                       # turn it off
        speak("–°—ç–Ω—Å —É–Ω—Ç—Ä–∞–∞–ª–∞–∞")
        info_label.configure(text="–°—ç–Ω—Å: –£–ù–¢–†–ê–ê (–ì–æ–ª–æ—Å)")

# =============================================
# GUI
# =============================================
ctk.set_appearance_mode("dark")
ctk.set_default_color_theme("blue")
app = ctk.CTk()
app.title("–¶–∞–≥ –±“Ø—Ä—Ç–≥—ç–ª–∏–π–Ω —Å–∏—Å—Ç–µ–º")
app.update_idletasks()
app.geometry(f"{app.winfo_screenwidth()}x{app.winfo_screenheight()}+0+0")
app.attributes("-fullscreen", True)
app.attributes("-topmost", True)
app.config(cursor="none")
app.focus_force()

app.bind("<Escape>", lambda e: app.attributes("-fullscreen", False))

bg_image = ctk.CTkImage(
    light_image=PILImage.open("background.jpg"),
    dark_image=PILImage.open("background.jpg"),
    size=(app.winfo_screenwidth(), app.winfo_screenheight())
)

bg_label = ctk.CTkLabel(app, image=bg_image, text="")
bg_label.place(x=0, y=0, relwidth=1, relheight=1)
bg_label.lower()

# Clock
date_label = ctk.CTkLabel(app, text="", font=("Noto Sans CJK JP", 24), text_color="#00DDFF")
date_label.pack(pady=(0))
time_label = ctk.CTkLabel(app, text="", font=("Noto Sans CJK JP", 32, "bold"), text_color="#2288ff")
time_label.pack(pady=(0))

# =============================================
# STATUS INDICATORS (Top Right Corner) - Full Connection + Active Check
# =============================================
status_frame = ctk.CTkFrame(app, fg_color="transparent")
status_frame.place(relx=1.0, rely=0.0, anchor="ne", x=-20, y=20)

mic_label = ctk.CTkLabel(status_frame, text="üéôÔ∏è ‚óè", font=("Arial", 28), text_color="red")
mic_label.grid(row=0, column=0, padx=15)

speaker_label = ctk.CTkLabel(status_frame, text="üîä ‚óè", font=("Arial", 28), text_color="red")
speaker_label.grid(row=0, column=1, padx=15)

camera_label = ctk.CTkLabel(status_frame, text="üì∑ ‚óè", font=("Arial", 28), text_color="red")
camera_label.grid(row=0, column=2, padx=15)

# Hover tooltip
mic_label.bind("<Enter>", lambda e: info_label.configure(text="–ú–∏–∫—Ä–æ—Ñ–æ–Ω"))
mic_label.bind("<Leave>", lambda e: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))
speaker_label.bind("<Enter>", lambda e: info_label.configure(text="–ß–∞–Ω–≥–∞ —è—Ä–∏–≥—á"))
speaker_label.bind("<Leave>", lambda e: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))
camera_label.bind("<Enter>", lambda e: info_label.configure(text="–ö–∞–º–µ—Ä"))
camera_label.bind("<Leave>", lambda e: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))

# –•–æ–ª–±–æ–ª—Ç —à–∞–ª–≥–∞—Ö —Ñ—É–Ω–∫—Ü—É—É–¥ (–∑–∞—Å–≤–∞—Ä—Ç–∞–π ‚Äì –∏–ª“Ø“Ø –Ω–∞–π–¥–≤–∞—Ä—Ç–∞–π)
def check_microphone():
    try:
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        cap.release()
        return ret
    except:
        return False

def check_speaker():
    try:
        # bluetoothctl devices Connected –∫–æ–º–∞–Ω–¥—ã–≥ –∞—à–∏–≥–ª–∞–∂, —Ö–æ–ª–±–æ–≥–¥—Å–æ–Ω —Ç”©—Ö”©”©—Ä”©–º–∂“Ø“Ø–¥–∏–π–≥ –∞–≤–Ω–∞
        result = os.popen("bluetoothctl devices Connected").read().strip()
        
        if not result:
            return False  # –Ø–º–∞—Ä —á —Ç”©—Ö”©”©—Ä”©–º–∂ —Ö–æ–ª–±–æ–≥–¥–æ–æ–≥“Ø–π
        
        # –•–æ–ª–±–æ–≥–¥—Å–æ–Ω —Ç”©—Ö”©”©—Ä”©–º–∂“Ø“Ø–¥–∏–π–Ω MAC address-—É—É–¥—ã–≥ –∞–≤–Ω–∞
        connected_macs = [line.split()[1] for line in result.splitlines() if line.strip()]
        
        # –¢—É—Å –±“Ø—Ä–∏–π–Ω info-–≥ —à–∞–ª–≥–∞–∂, –∞—É–¥–∏–æ —Ç”©—Ö”©”©—Ä”©–º–∂ —ç—Å—ç—Ö–∏–π–≥ —Ö–∞—Ä–Ω–∞
        for mac in connected_macs:
            info = os.popen(f"bluetoothctl info {mac}").read()
            if "Connected: yes" in info and ("Icon: audio" in info.lower() or "UUID: Audio" in info):
                return True
        
        return False
    except Exception as e:
        print("Bluetooth —Å–ø–∏–∫–µ—Ä —à–∞–ª–≥–∞–ª—Ç –∞–ª–¥–∞–∞:", e)
        return False

def check_camera():
    try:
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        cap.release()
        return ret
    except:
        return False

# –ì–ª–æ–±–∞–ª —Ç”©–ª”©–≤“Ø“Ø–¥
mic_connected = False
speaker_connected = False
camera_connected = False
camera_active = False     # –û–¥–æ–æ –∞—à–∏–≥–ª–∞–∂ –±–∞–π–≥–∞–∞ —ç—Å—ç—Ö
ai_listening = False         # –≥–ª–æ–±–∞–ª —Ç”©–ª”©–≤
ai_thread = None             # thread —Ö–∞–¥–≥–∞–ª–∞—Ö
ai_transcript = ""           # –±“Ø—Ö —è—Ä–∏–≥–¥—Å–∞–Ω —Ç–µ–∫—Å—Ç

# –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —à–∏–Ω—ç—á–ª—ç—Ö —Ñ—É–Ω–∫—Ü ‚Äì –∑”©–≤ –¥—É—É–¥–∞–≥–¥–∞–Ω–∞
def update_status_indicators():
    global mic_connected, speaker_connected, camera_connected, camera_active

    if not camera_active:
        current_connected = check_camera()
        if current_connected != camera_connected:
            camera_connected = current_connected
            color = "red" if not camera_connected else "gray"
            camera_label.configure(text_color=color)

    # –ö–∞–º–µ—Ä –∏–¥—ç–≤—Ö—Ç—ç–π –±–æ–ª —è–≥ –Ω–æ–≥–æ–æ–Ω —Ö—ç–≤—ç—ç—Ä –±–∞–π–ª–≥–∞–Ω–∞
    if camera_active and camera_connected:
        camera_label.configure(text_color="green")

    # –ú–∏–∫—Ä–æ—Ñ–æ–Ω
    current_mic = check_microphone()
    if current_mic:
        mic_color = "green" if ai_listening else "gray"
    else:
        mic_color = "red"
    mic_label.configure(text_color=mic_color)
    mic_connected = current_mic

    # –ß–∞–Ω–≥–∞ —è—Ä–∏–≥—á
    current_speaker = check_speaker()
    if current_speaker:
        # speak() –¥–æ—Ç–æ—Ä –Ω–æ–≥–æ–æ–Ω –±–æ–ª–≥–æ–Ω–æ
        speaker_color = "gray"  # default —Å–∞–∞—Ä–∞–ª (speak() –¥–æ—Ç–æ—Ä –Ω–æ–≥–æ–æ–Ω –±–æ–ª–≥–æ–Ω–æ)
    else:
        speaker_color = "red"
    speaker_label.configure(text_color=speaker_color)
    speaker_connected = current_speaker


    # 3 —Å–µ–∫—É–Ω–¥ —Ç—É—Ç–∞–º –¥–∞—Ö–∏–Ω —à–∞–ª–≥–∞–Ω–∞
    app.after(3000, update_status_indicators)

# –ê–ø–ø —ç—Ö–ª—ç—Ö—ç–¥ —à–∞–ª–≥–∞–ª—Ç —ç—Ö—ç–ª–Ω—ç
update_status_indicators()


def update_clock():
    now = datetime.datetime.now()
    date_label.configure(text=now.strftime("%A, %B %d, %Y"))
    time_label.configure(text=now.strftime("%H:%M:%S"))
    app.after(1000, update_clock)
update_clock()

info_label = ctk.CTkLabel(app, text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É", font=("Noto Sans CJK JP", 24), text_color="#CCFFCC")
info_label.pack(pady=0)

# Temperature label
temp_label = ctk.CTkLabel(app, text="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä: --¬∞C", font=("Noto Sans CJK JP", 20), text_color="#FFAA00")
temp_label.pack(pady=0)

# =============================================
# DHT11 + Auto Fan + Auto Light
# =============================================
def read_temp():
    for _ in range(10):
        try:
            temp = dht_device.temperature
            hum = dht_device.humidity
            if temp is not None:
                return temp, hum
        except:
            time.sleep(0.5)
    return None, None

def update_temp_and_control():
    global manual_fan, light_auto_on
    temp, hum = read_temp()
    if temp is not None:
        
        
        temp_label.configure(text=f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä: {temp:.1f}¬∞C | –ß–∏–π–≥—à–∏–ª: {hum:.1f}%")

        # Auto Fan (only if not manually not overridden)
        if not manual_fan:
            if temp > TEMP_THRESHOLD and GPIO.input(FAN_PIN) == GPIO.HIGH:
                GPIO.output(FAN_PIN, GPIO.LOW)
                beep(2)   # ‚Üê ADD THIS
                sens1_btn.configure(text="–°—ç–Ω—Å: –ê–°–õ–ê–ê (–ê–≤—Ç–æ)")
            elif temp <= TEMP_THRESHOLD and GPIO.input(FAN_PIN) == GPIO.LOW:
                GPIO.output(FAN_PIN, GPIO.HIGH)
                beep(1)   # ‚Üê ADD THIS
                sens1_btn.configure(text="–°—ç–Ω—Å: –£–ù–¢–†–ê–ê (–ê–≤—Ç–æ)")

        # Auto Light - first person in = ON, last person out = OFF
        if active_workers and not light_auto_on:
            GPIO.output(LIGHT_PIN, GPIO.LOW)
            beep(1)   # ‚Üê short beep when person enters
            gerel_btn.configure(text="–ì—ç—Ä—ç–ª: –ê–°–õ–ê–ê (–ê–≤—Ç–æ)")
            light_auto_on = True
        elif not active_workers and light_auto_on:
            GPIO.output(LIGHT_PIN, GPIO.HIGH)
            beep(2)   # ‚Üê short beep when person enters
            gerel_btn.configure(text="–ì—ç—Ä—ç–ª: –£–ù–¢–†–ê–ê (–ê–≤—Ç–æ)")
            light_auto_on = False

    app.after(5000, update_temp_and_control)
    
    



# =============================================
# Buttons
# =============================================
# def toggle_sens1():
#     beep(2)          # 2 beeps when turning ON, 1 when OFF
    
#     global manual_fan
#     manual_fan = True
#     current = GPIO.input(FAN_PIN)
#     GPIO.output(FAN_PIN, not current)
#     # ‚Üê‚Üê‚Üê ADD THESE TWO LINES ‚Üì‚Üì‚Üì
#     # ‚Üê‚Üê‚Üê
#     state = "–ê–°–õ–ê–ê" if not current else "–£–ù–¢–†–ê–ê"
#     sens1_btn.configure(text=f"–°—ç–Ω—Å: {state} (–ì–∞—Ä–∞–∞—Ä)")
#     speak("–°—ç–Ω—Å " + ("–∞—Å–∞–∞–ª–∞–∞" if not current else "—É–Ω—Ç—Ä–∞–∞–ª–∞–∞"))

# def toggle_gerel():
#     beep(2)          # 1 beep when turning ON, 2 when OFF
    
#     current = GPIO.input(LIGHT_PIN)
#     GPIO.output(LIGHT_PIN, not current)
#     # ‚Üê‚Üê‚Üê ADD THESE TWO LINES ‚Üì‚Üì‚Üì
#     # ‚Üê‚Üê‚Üê
#     state = "–ê–°–õ–ê–ê" if not current else "–£–ù–¢–†–ê–ê"
#     gerel_btn.configure(text=f"–ì—ç—Ä—ç–ª: {state} (–ì–∞—Ä–∞–∞—Ä)")
#     speak("–ì—ç—Ä—ç–ª " + ("–∞—Å–∞–∞–ª–∞–∞" if not current else "—É–Ω—Ç—Ä–∞–∞–ª–∞–∞"))
    
def toggle_sens1():
    print("Fan toggle pressed")
    global manual_fan
    manual_fan = True
    was_on = GPIO.input(FAN_PIN) == GPIO.LOW
    GPIO.output(FAN_PIN, not GPIO.input(FAN_PIN))
    beep(2 if not was_on else 1)
    state = "–ê–°–õ–ê–ê" if not was_on else "–£–ù–¢–†–ê–ê"
    sens1_btn.configure(text=f"–°—ç–Ω—Å: {state} (–ì–∞—Ä–∞–∞—Ä)")
    speak("–°—ç–Ω—Å " + ("–∞—Å–∞–∞–ª–∞–∞" if not was_on else "—É–Ω—Ç—Ä–∞–∞–ª–∞–∞"))

def toggle_gerel():
    print("Light toggle pressed")
    was_on = GPIO.input(LIGHT_PIN) == GPIO.LOW
    GPIO.output(LIGHT_PIN, not GPIO.input(LIGHT_PIN))
    beep(1 if not was_on else 2)
    state = "–ê–°–õ–ê–ê" if not was_on else "–£–ù–¢–†–ê–ê"
    gerel_btn.configure(text=f"–ì—ç—Ä—ç–ª: {state} (–ì–∞—Ä–∞–∞—Ä)")
    speak("–ì—ç—Ä—ç–ª " + ("–∞—Å–∞–∞–ª–∞–∞" if not was_on else "—É–Ω—Ç—Ä–∞–∞–ª–∞–∞"))
# -------------------------------------------------
# 1. Add New Worker ‚Äì AUTO FACE DETECT + CAPTURE
# -------------------------------------------------
pending_photo_path = None

def add_worker():
    global pending_photo_path
    global camera_active
    camera_active = True
    if camera_connected:
        camera_label.configure(text_color="green")
    info_label.configure(text="–ö–∞–º–µ—Ä–ª—É—É —Ö–∞—Ä–∞–∞—Ä–∞–π...")
    app.update()

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        info_label.configure(text="–ö–∞–º–µ—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
        return

    preview = ctk.CTkToplevel(app)
    preview.title("–®–∏–Ω—ç –∞–∂–∏–ª—Ç–∞–Ω –Ω—ç–º—ç—Ö")
    preview.attributes("-fullscreen", True)
    preview.configure(bg="black")
    preview.focus_force()
    preview.config(cursor="none")
    preview.bind("<Escape>", lambda e: preview.destroy())
    camera_active = False
    color = "gray" if camera_connected else "red"
    camera_label.configure(text_color=color)
    cam_label = ctk.CTkLabel(preview, text="")
    cam_label.pack()
    cam_label.pack(expand=True, fill="both")     # ‚Üê make video fill the whole screen

    captured = [None]
    captured_time = [0]

    def show():
        current_time = time.time()
        if captured[0] is not None:
            frame = captured[0].copy()  # Static photo
            # Redraw box on static
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            locations = face_recognition.face_locations(rgb)
            for (top, right, bottom, left) in locations:
                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(frame, "Unknown", (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        else:
            ret, frame = cap.read()
            if not ret:
                preview.after(30, show)
                return
            frame = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            locations = face_recognition.face_locations(rgb)
            # Draw box
            for (top, right, bottom, left) in locations:
                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(frame, "Unknown", (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            # Auto-capture if face detected and timeout passed
            if locations and current_time - captured_time[0] > 1:  # 1 sec debounce
                captured[0] = frame.copy()
                captured_time[0] = current_time
                info_label.configure(text="–¶–∞—Ä–∞–π —Ç–∞–Ω–∏–≥–¥–ª–∞–∞! –î–∞—Ö–∏–Ω —Ç–∞–Ω–∏—É–ª–∞—Ö —ç—Å–≤—ç–ª –•–∞–¥–≥–∞–ª–∞—Ö?")
                speak("–ó—É—Ä–∞–≥ –∞–≤–ª–∞–∞")

        img = ctk.CTkImage(light_image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)),
                           dark_image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)),
                           size=(640, 360))
        cam_label.configure(image=img)
        cam_label.image = img
        preview.after(30, show)

    show()

    btns = ctk.CTkFrame(preview)
    btns.pack(pady=8)
    ctk.CTkButton(btns, text="–î–∞—Ö–∏–Ω —Ç–∞–Ω–∏—É–ª–∞—Ö", command=lambda: reset_capture(captured, captured_time)).grid(row=0, column=0, padx=8)
    ctk.CTkButton(btns, text="–•–∞–¥–≥–∞–ª–∞—Ö", command=lambda: save_photo_and_form(captured[0], cap, preview)).grid(row=0, column=1, padx=8)

    def reset_capture(captured, captured_time):
        captured[0] = None
        captured_time[0] = 0
        info_label.configure(text="–ö–∞–º–µ—Ä–ª—É—É –∞—Ö–∏–∞–¥ —Ö–∞—Ä–∞–∞—Ä–∞–π...")

    def save_photo_and_form(photo_frame, cap, preview_win):
        global pending_photo_path
        camera_label.configure(text_color="gray")
        cap.release()
        preview_win.destroy()

        if photo_frame is None:
            info_label.configure(text="–¶–∞—Ä–∞–π —Ç–∞–Ω–∏—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞! –î–∞—Ö–∏–∞–¥ –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")
            return

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        pending_photo_path = f"pending_photos/photo_{timestamp}.jpg"
        cv2.imwrite(pending_photo_path, photo_frame)
        info_label.configure(text="–ó—É—Ä–∞–≥ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞! –ê–∂–∏–ª—Ç–Ω—ã –º—ç–¥—ç—ç–ª—ç–ª–∏–π–≥ –æ—Ä—É—É–ª–Ω–∞ —É—É.")
        open_registration_form()

# -------------------------------------------------
# Registration Form
# -------------------------------------------------
# -------------------------------------------------
# Registration Form ‚Äì FULLSCREEN + WORKING KEYBOARD
# -------------------------------------------------
# -------------------------------------------------
# –¢”®–ì–° –ë“Æ–†–¢–ì–≠–õ–ò–ô–ù –§–û–†–ú ‚Äì –ë“Æ–†–≠–ù –î–≠–õ–ì–≠–¶, –°–ö–†–û–õ–õ–¢–û–ô, –ê–ñ–ò–õ–õ–ê–î–ê–ì –ì–ê–†
# -------------------------------------------------
# -------------------------------------------------
# –≠–¶–°–ò–ô–ù –¢”®–ì–° –ë“Æ–†–¢–ì–≠–õ–ò–ô–ù –§–û–†–ú ‚Äì –ó”®–í–•”®–ù 1 –¢–û–í–ß, ”®”®–†–ò–ô–ù –ì–ê–†
# -------------------------------------------------
# -------------------------------------------------
# –¢”®–ì–° –ë“Æ–†–¢–ì–≠–õ–ò–ô–ù –§–û–†–ú ‚Äì FLORENCE –ì–ê–† (—Ç–æ–æ, “Ø—Å—ç–≥, –º–æ–Ω–≥–æ–ª, –¥–æ–æ–¥ —Ç–∞–ª–¥–∞–∞, –∞–ª–≥–∞ –±–æ–ª–æ—Ö–≥“Ø–π)
# -------------------------------------------------
# -------------------------------------------------
# –¢”®–ì–° –ë“Æ–†–¢–ì–≠–õ–ò–ô–ù –§–û–†–ú ‚Äì –°–ò–°–¢–ï–ú–ò–ô–ù ”®”®–†–ò–ô–ù –ì–ê–† (Chrome —à–∏–≥)
# -------------------------------------------------
# -------------------------------------------------
# –¢”®–ì–° CUSTOM KEYBOARD + –ë“Æ–†–¢–ì–≠–õ–ò–ô–ù –§–û–†–ú (2025 –æ–Ω–¥ 100% –∞–∂–∏–ª–ª–∞–Ω–∞)
# -------------------------------------------------
current_entry = None

def show_custom_keyboard(entry_widget):
    global current_entry
    current_entry = entry_widget

    for widget in app.winfo_children():
        if isinstance(widget, ctk.CTkToplevel) and widget.title() == "–ú—É–Ω–¥–∞–≥ —Ö–æ—Å–æ–æ–≥–∏–π–Ω –∫—ç–µ–±–æ—Ä–¥":
            widget.destroy()

    screen_w = app.winfo_screenwidth()
    screen_h = app.winfo_screenheight()

    kb_height = int(screen_h * 0.35)   # smaller keyboard
    kb_y = screen_h - kb_height        # fix to bottom

    kb = ctk.CTkToplevel(app)
    kb.title("Khosbayar's keyboard")
    kb.geometry(f"{screen_w}x{kb_height}+0+{kb_y}")
    kb.configure(fg_color="#1e1e2e")
    kb.resizable(False, False)

    keys = [
        ['1','2','3','4','5','6','7','8','9','0'],
        ['q','w','e','r','t','y','u','i','o','p'],
        ['a','s','d','f','g','h','j','k','l'],
        ['z','x','c','v','b','n','m',',','.'],
        ['Backspace','Space','Clear','Close']
    ]

    def press(k):
        if current_entry is None:
            return
        if k == "Backspace":
            current_entry.delete(0, 'end')
            current_entry.insert(0, current_entry.get()[:-1])
        elif k == "Space":
            current_entry.insert("end", " ")
        elif k == "Clear":
            current_entry.delete(0, "end")
        elif k == "Close":
            kb.destroy()
        else:
            current_entry.insert("end", k)

    for row in keys:
        row_frame = ctk.CTkFrame(kb, fg_color="#1e1e2e")
        row_frame.pack(pady=1)

        for key in row:
            if key == "Space":
                btn = ctk.CTkButton(row_frame, text="", width=350, height=45,
                                    fg_color="#444444", command=lambda: press(" "))
            elif key in ["Backspace", "Clear", "Close"]:
                color = "#cc0000" if key in ["Clear", "Close"] else "#0066ff"
                btn = ctk.CTkButton(row_frame, text=key, width=130, height=45,
                                    font=("Arial", 20, "bold"), fg_color=color,
                                    command=lambda k=key: press(k))
            else:
                btn = ctk.CTkButton(row_frame, text=key.upper(), width=60, height=45,
                                    font=("Arial", 24, "bold"), fg_color="#333333",
                                    command=lambda k=key: press(k))
            btn.pack(side="left", padx=3)
            
def open_registration_form():
    global pending_photo_path
    if not pending_photo_path or not os.path.exists(pending_photo_path):
        info_label.configure(text="–ó—É—Ä–∞–≥ –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
        return

    form = ctk.CTkToplevel(app)
    form.title("")
    form.geometry(f"{app.winfo_screenwidth()}x{app.winfo_screenheight()}+0+0")
    form.configure(fg_color="#0d1117")
    form.resizable(False, False)

    # Centered main container ‚Äì no left/right split anymore
    main_container = ctk.CTkFrame(form, fg_color="#0d1117")
    main_container.pack(fill="both", expand=True)

    # Title
    ctk.CTkLabel(main_container, text="–®–ò–ù–≠ –ê–ñ–ò–õ–¢–ê–ù –ë“Æ–†–¢–ì–≠–•",
                 font=("Noto Sans CJK JP", 32, "bold"),
                 text_color="#00ffaa").pack(pady=10)

    # Compact 2√ó2 grid centered
    grid = ctk.CTkFrame(main_container, fg_color="transparent")
    grid.pack(pady=5)

    entries = {}
    fields = ["Full Name", "Employee ID", "Department", "Position"]

    for i, field in enumerate(fields):
        row = i // 2
        col = i % 2

        ctk.CTkLabel(grid, text=field + ":",
                     font=("Noto Sans CJK JP", 20),
                     text_color="white").grid(
            row=row*2, column=col, padx=40, pady=(5, 0), sticky="w"
        )

        entry = ctk.CTkEntry(grid, width=350, height=55,
                             font=("Noto Sans CJK JP", 22),
                             fg_color="white", text_color="black",
                             corner_radius=10, border_width=2)
        entry.grid(row=row*2+1, column=col,
                   padx=40, pady=(0, 10), sticky="w")
        entry.bind("<Button-1>", lambda e, w=entry: show_custom_keyboard(w))

        entries[field] = entry

    # Save button centered
    def save():
        name = entries["Full Name"].get().strip()
        if not name:
            speak("–ù—ç—Ä—ç—ç –±–∏—á–Ω—ç “Ø“Ø")
            return
        safe = name.replace(" ", "_")
        shutil.move(pending_photo_path, f"known_faces/{safe}.jpg")
        with open(f"worker_data/{safe}.txt", "w", encoding="utf-8") as f:
            for k, v in entries.items():
                f.write(f"{k}: {v.get().strip()}\n")

        global known_face_encodings, known_face_names
        known_face_encodings, known_face_names = load_known_faces()

        speak(f"{name} –±“Ø—Ä—Ç–≥—ç–≥–¥–ª—ç—ç")
        info_label.configure(text=f"{name} ‚úì")
        form.destroy()

    ctk.CTkButton(main_container, text="–ë“Æ–†–¢–ì–≠–•", command=save,
                  width=400, height=70,
                  font=("Noto Sans CJK JP", 28, "bold"),
                  fg_color="#00aa33", hover_color="#008822").pack(pady=20)

    form.protocol("WM_DELETE_WINDOW", form.destroy)

# -------------------------------------------------
# 2. Show All Logs
# -------------------------------------------------
def show_all_logs():
    log_win = ctk.CTkToplevel(app)
    log_win.title("–ò—Ä—Ü–∏–π–Ω –±“Ø—Ä—Ç–≥—ç–ª")
    log_win.geometry("780x580")
    txt = ctk.CTkTextbox(log_win, font=("Courier", 14))
    txt.pack(fill="both", expand=True, padx=12, pady=12)
    if os.path.exists("time_logs.txt"):
        with open("time_logs.txt", "r", encoding="utf-8") as f:
            lines = f.readlines()
        header = f"{'Name':<20} {'Action':<8} {'Timestamp':<20}\n"
        header += "-"*52 + "\n"
        txt.insert("end", header)
        for line in lines:
            parts = line.strip().split(",", 2)
            if len(parts) == 3:
                name, action, ts = parts
                txt.insert("end", f"{name:<20} {action:<8} {ts:<20}\n")
    else:
        txt.insert("end", "–ë“Ø—Ä—Ç–≥—ç–ª —Ö–æ–æ—Å–æ–Ω –±–∞–π–Ω–∞.\n")

# -------------------------------------------------
# 3. Recognize Face ‚Äì SHOW USERNAME + RETAKE/SAVE
# -------------------------------------------------
active_workers = {}

def recognize_once():
    global active_workers
    global camera_active
    camera_active = True
    if camera_connected:
        camera_label.configure(text_color="green")
    info_label.configure(text="–ö–∞–º–µ—Ä–ª—É—É —Ö–∞—Ä–∞–∞—Ä–∞–π...")
    app.update()

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        info_label.configure(text="–ö–∞–º–µ—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
        return

    preview = ctk.CTkToplevel(app)
    preview.title("–¶–∞—Ä–∞–π —Ç–∞–Ω–∏—Ö")
    preview.attributes("-fullscreen", True)        # FULLSCREEN
    preview.configure(bg="black")
    preview.focus_force()
    # Hide mouse cursor in camera mode (optional but nice)
    preview.config(cursor="none")

    # Optional: press Escape to close camera
    preview.bind("<Escape>", lambda e: preview.destroy())
    cam_label = ctk.CTkLabel(preview, text="")
    cam_label.pack()

    captured = [None]
    detected_name = [None]
    captured_time = [0]

    def show():
        current_time = time.time()
        if captured[0] is not None:
            frame = captured[0].copy()  # Static photo
            # Redraw box + name on static
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            locations = face_recognition.face_locations(rgb)
            for (top, right, bottom, left) in locations:
                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(frame, detected_name[0] or "Unknown", (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        else:
            ret, frame = cap.read()
            if not ret:
                preview.after(30, show)
                return
            frame = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            locations = face_recognition.face_locations(rgb)
            encodings = face_recognition.face_encodings(rgb, locations)

            name = "Unknown"
            if encodings:
                matches = face_recognition.compare_faces(known_face_encodings, encodings[0], tolerance=0.55)
                if True in matches:
                    idx = matches.index(True)
                    name = known_face_names[idx]
                detected_name[0] = name

            # Draw box + name
            for (top, right, bottom, left) in locations:
                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            # Auto-capture if face detected and timeout passed
            if locations and current_time - captured_time[0] > 1:  # 1 sec debounce
                captured[0] = frame.copy()
                captured_time[0] = current_time
                info_label.configure(text=f"{name} —Ç–∞–Ω–∏–≥–¥–ª–∞–∞! –ë“Ø—Ä—Ç–≥—ç—Ö —ç—Å–≤—ç–ª –¥–∞—Ö–∏–Ω –∞–≤–∞—Ö?")
                speak("–ó—É—Ä–∞–≥ –∞–≤–ª–∞–∞")

        img = ctk.CTkImage(light_image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)),
                           dark_image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)),
                           size=(640, 360))
        cam_label.configure(image=img)
        cam_label.image = img
        preview.after(30, show)

    show()

    btns = ctk.CTkFrame(preview)
    btns.pack(pady=8)
    ctk.CTkButton(btns, text="–î–∞—Ö–∏–Ω –∞–≤–∞—Ö", command=lambda: reset_recognition(captured, captured_time)).grid(row=0, column=0, padx=8)
    ctk.CTkButton(btns, text="–ë“Ø—Ä—Ç–≥—ç—Ö", command=lambda: save_and_log(captured[0], detected_name[0], cap, preview)).grid(row=0, column=1, padx=8)

    def reset_recognition(captured, captured_time):
        captured[0] = None
        captured_time[0] = 0
        info_label.configure(text="–ö–∞–º–µ—Ä–ª—É—É —Ö–∞—Ä–∞–∞—Ä–∞–π...")

    def save_and_log(photo_frame, name, cap, preview_win):
        global active_workers
        cap.release()
        preview_win.destroy()

        if photo_frame is None:
            info_label.configure(text="–¶–∞—Ä–∞–π —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω–≥“Ø–π! –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ—Ö.")
            return

        if name == "Unknown":
            speak("–¢–∞–Ω–∏—Ö–≥“Ø–π —Ö“Ø–Ω")
            info_label.configure(text="Unknown face")
            return

        if name not in active_workers:
            ts = log_time(name, "IN")
            active_workers[name] = ts
            beep(1)                                # ‚Üê 1 beep = welcome
            speak(f"{name} –∏—Ä–ª—ç—ç")
            info_label.configure(text=f"{name} ‚Äì IN at {ts.split()[1]}")
        else:
            active_workers.pop(name)
            out_ts = log_time(name, "OUT")
            beep(2)                                # ‚Üê 2 beeps = goodbye
            speak(f"{name} —è–≤–ª–∞–∞")
            info_label.configure(text=f"{name} ‚Äì OUT at {out_ts.split()[1]}")
        global camera_active
        camera_active = False
        color = "gray" if camera_connected else "red"
        camera_label.configure(text_color=color)
        app.after(2000, lambda: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))

# -------------------------------------------------
# 4. Sens1 & Gerel Toggle Buttons
# -------------------------------------------------
sens1_state = False
gerel_state = False

# ---------- Fan ----------
# ---------- Fan (–°—ç–Ω—Å) ----------
# def toggle_sens1():
#     global manual_fan  # This disables auto control when pressed
#     manual_fan = True
    
#     current = GPIO.input(FAN_PIN)
#     GPIO.output(FAN_PIN, not current)
    
#     state = "–ê–°–õ–ê–ê" if not current else "–£–ù–¢–†–ê–ê"
#     sens1_btn.configure(text=f"–°—ç–Ω—Å: {state} (–ì–∞—Ä–∞–∞—Ä)")
#     speak("–°—ç–Ω—Å –Ω—ç–≥ " + ("–∞—Å–∞–∞–ª–∞–∞" if not current else "—É–Ω—Ç—Ä–∞–∞–ª–∞–∞"))

# # ---------- Light (–ì—ç—Ä—ç–ª) ----------
# def toggle_gerel():
#     current = GPIO.input(LIGHT_PIN)
#     GPIO.output(LIGHT_PIN, not current)
#     state = "–ê–°–õ–ê–ê" if not current else "–£–ù–¢–†–ê–ê"
#     gerel_btn.configure(text=f"–ì—ç—Ä—ç–ª: {state} (–ì–∞—Ä–∞–∞—Ä)")
#     speak("–ì—ç—Ä—ç–ª " + ("–∞—Å–∞–∞–ª–∞–∞" if not current else "—É–Ω—Ç—Ä–∞–∞–ª–∞–∞"))
# -------------------------------------------------
# Gemini Assistant Button Functionality
# -------------------------------------------------
# ==================== AI –¢–û–í–ß ‚Äì –¢–ê–°–†–ê–õ–¢–ì“Æ–ô –°–û–ù–°–û–û–î –î–ê–†–ê–ê –ù–¨ –ò–õ–ì–≠–≠–• ====================


def toggle_ai():
    global ai_listening, ai_thread, ai_transcript

    if not ai_listening:                               # ‚Äî‚Äî –≠–•–õ“Æ“Æ–õ–≠–• ‚Äî‚Äî
        ai_listening = True
        ai_transcript = ""
        ai_btn.configure(text="AI –ó–û–ì–°", fg_color="#FF3333", hover_color="#CC0000")
        info_label.configure(text="–°–æ–Ω—Å–æ–∂ –±–∞–π–Ω–∞... —è—Ä—å–∂ —ç—Ö—ç–ª–Ω—ç “Ø“Ø")
        speak("–°–æ–Ω—Å–æ–∂ –±–∞–π–Ω–∞")

        # –¢—É—Å–¥–∞–∞ thread –¥—ç—ç—Ä —Ç–∞—Å—Ä–∞–ª—Ç–≥“Ø–π —Å–æ–Ω—Å–æ–Ω–æ
        ai_thread = threading.Thread(target=continuous_listen, daemon=True)
        ai_thread.start()

    else: # ‚Äî‚Äî –ó–û–ì–°–û–û–• + –ò–õ–ì–≠–≠–• ‚Äî‚Äî
        ai_listening = False
        ai_btn.configure(text="AI –∞–∂–∏–ª–ª—É—É–ª–∞—Ö", fg_color="#AA00FF", hover_color="#8800CC")
        # –≠–Ω–¥ —é—É —á –±–∏—á–∏—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞–≥“Ø–π ‚Äì continuous_listen –¥–æ—Ç–æ—Ä –±“Ø–≥–¥ –∑–æ—Ö–∏—Ü—É—É–ª–∞–≥–¥–∞–Ω–∞

def continuous_listen():
    """–¢–æ–≤—á –¥–∞—Ä–∞—Ö —Ö“Ø—Ä—Ç—ç–ª —Ç–∞—Å—Ä–∞–ª—Ç–≥“Ø–π —Å–æ–Ω—Å–æ–æ–¥ —Ç–µ–∫—Å—Ç–∏–π–≥ –Ω—ç–≥—Ç–≥—ç–Ω—ç"""
    global ai_transcript
    r = sr.Recognizer()
    r.energy_threshold = 300
    r.dynamic_energy_threshold = True

    with sr.Microphone() as source:
        r.adjust_for_ambient_noise(source, duration=1.0)
        print("[AI] –°–æ–Ω—Å–æ–æ–∂ —ç—Ö—ç–ª–ª—ç—ç...")

        ai_transcript = ""

        while ai_listening:
            try:
                audio = r.listen(source, timeout=1.0, phrase_time_limit=15)
                text = r.recognize_google(audio, language="mn-MN")
                ai_transcript += text + " "

                # –ë–æ–¥–∏—Ç —Ü–∞–≥—Ç —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —è—Ä—å–∂ –±–∞–π–≥–∞–∞ —Ç–µ–∫—Å—Ç–∏–π–≥ info_label –¥—ç—ç—Ä —Ö–∞—Ä—É—É–ª–Ω–∞
                app.after(0, lambda t=ai_transcript.strip(): info_label.configure(
                    text=f"–¢–∞–Ω—ã —Ö—ç–ª—Å—ç–Ω: {t[-80:]}" if len(t) > 80 else f"–¢–∞–Ω—ã —Ö—ç–ª—Å—ç–Ω: {t}"
                ))

            except sr.WaitTimeoutError:
                continue
            except sr.UnknownValueError:
                continue
            except Exception as e:
                print("–°–æ–Ω—Å–æ—Ö –∞–ª–¥–∞–∞:", e)
                continue

    # ‚Äî‚Äî –Ø—Ä–∏–∞ –¥—É—É—Å–ª–∞–∞ (—Ç–æ–≤—á –¥–∞—Ä–∞–≥–¥–ª–∞–∞) ‚Äî‚Äî
    if ai_transcript.strip():
        user_text = ai_transcript.strip()

        # –≠—Ü—Å–∏–π–Ω —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Ç–µ–∫—Å—Ç–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
        app.after(0, lambda: info_label.configure(
            text=f"–¢–∞–Ω—ã —Ö—ç–ª—Å—ç–Ω: {user_text[-90:]}" if len(user_text) > 90 else f"–¢–∞–Ω—ã —Ö—ç–ª—Å—ç–Ω: {user_text}"
        ))

        # –ì—ç—Ä—ç–ª/–°—ç–Ω—Å –∫–æ–º–∞–Ω–¥ —à–∞–ª–≥–∞—Ö
        if any(keyword in user_text.lower() for keyword in ["–≥—ç—Ä—ç–ª", "—Å—ç–Ω—Å", "light", "fan"]):
            process_voice_command(user_text)
            app.after(3000, lambda: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))
            return

        # Gemini —Ä“Ø“Ø –∏–ª–≥—ç—ç—Ö
        app.after(0, lambda: info_label.configure(text="GROK –±–æ–¥–æ–∂ –±–∞–π–Ω–∞..."))

        response = ask_google_ai(user_text)

        # 2 —Å–µ–∫—É–Ω–¥—ã–Ω –¥–∞—Ä–∞–∞ Gemini —Ö–∞—Ä–∏—É–≥ —Ö–∞—Ä—É—É–ª–∞–∞–¥ —É–Ω—à–∏–Ω–∞
        def show_response():
            if response and len(response) > 0 and "—Ö—ç—Ç—ç—Ä–ª—ç—ç" not in response and "–∞–ª–¥–∞–∞" not in response.lower():
                display_text = response[:100] + "..." if len(response) > 100 else response
                info_label.configure(text=f"–•–∞—Ä–∏—É: {display_text}")
                speak(response)  # –û–¥–æ–æ background-–¥ –∞–∂–∏–ª–ª–∞–Ω–∞ ‚Üí label —à—É—É–¥ —Å–æ–ª–∏–≥–¥–æ–Ω–æ
            else:
                display_text = response[:100] + "..." if response and len(response) > 100 else (response or "–•–∞—Ä–∏—É –∏—Ä—Å—ç–Ω–≥“Ø–π")
                info_label.configure(text=f"–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞: {display_text}")
                speak(response or "–£—É—á–ª–∞–∞—Ä–∞–π, –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞")

            # –î—É—É –¥—É—É—Å–∞—Ö—ã–≥ —Ö“Ø–ª—ç—ç—Ö–≥“Ø–π ‚Äì 8 —Å–µ–∫—É–Ω–¥ —Ö“Ø–ª—ç—ç–≥—ç—ç–¥ –±—É—Ü–∞–∞–Ω–∞ (–¥—É—É–Ω—ã —É—Ä—Ç—Ç–∞–π —Ç–∞–∞—Ä—É—É–ª)
            app.after(8000, lambda: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))
            
            
        app.after(2000, show_response)  # –Ø–≥ 2 —Å–µ–∫—É–Ω–¥—ã–Ω –¥–∞—Ä–∞–∞

    else:
        app.after(0, lambda: info_label.configure(text="–Æ—É —á —Å–æ–Ω—Å—Å–æ–Ω–≥“Ø–π"))
        speak("–Æ—É —á —Å–æ–Ω—Å—Å–æ–Ω–≥“Ø–π")
        app.after(3000, lambda: info_label.configure(text="“Æ–π–ª–¥—ç–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É"))
        
        
# -------------------------------------------------
# Buttons Layout
# -------------------------------------------------
# –≠–Ω–¥—ç—ç—Å –¥–æ–æ—à –±“Ø—Ö —Ç–æ–≤—á–Ω—É—É–¥—ã–≥ —Ç–æ–º –±–æ–ª–≥–æ–Ω–æ
# =============================================
# Your existing code continues below (unchanged)
# =============================================
# ... [all your add_worker, registration, recognize_once, etc. functions here] ...

# Buttons at the bottom
# -------------------------------------------------
# Buttons Layout
# -------------------------------------------------
btn_frame = ctk.CTkFrame(app)
btn_frame.pack(pady=40)

BIG_BUTTON = {
    "width": 380,
    "height": 80,
    "font": ("Noto Sans CJK JP", 24, "bold"),
    "corner_radius": 20
}

ctk.CTkButton(btn_frame, text="–ê–∂–∏–ª—Ç–∞–Ω –Ω—ç–º—ç—Ö", command=add_worker, **BIG_BUTTON, fg_color="#00AA33").grid(row=0, column=0, padx=30, pady=15)
ctk.CTkButton(btn_frame, text="–ò—Ä—Ü–∏–π–Ω –±“Ø—Ä—Ç–≥—ç–ª", command=show_all_logs, **BIG_BUTTON, fg_color="#FF8800").grid(row=0, column=1, padx=30, pady=15)
ctk.CTkButton(btn_frame, text="–ù“Ø“Ø—Ä —Ç–∞–Ω–∏—Ö", command=recognize_once, **BIG_BUTTON, fg_color="#0066FF").grid(row=1, column=0, padx=30, pady=15)

# These buttons must exist BEFORE update_temp_and_control() is called!
sens1_btn = ctk.CTkButton(btn_frame, text="–°—ç–Ω—Å: –£–ù–¢–†–ê–ê", command=toggle_sens1, **BIG_BUTTON, fg_color="#888888")
sens1_btn.grid(row=1, column=1, padx=30, pady=15)

gerel_btn = ctk.CTkButton(btn_frame, text="–ì—ç—Ä—ç–ª: –£–ù–¢–†–ê–ê", command=toggle_gerel, **BIG_BUTTON, fg_color="#888888")
gerel_btn.grid(row=2, column=0, padx=30, pady=15)

ai_btn = ctk.CTkButton(btn_frame, text="AI –∞–∂–∏–ª–ª—É—É–ª–∞—Ö", command=toggle_ai, **BIG_BUTTON, fg_color="#AA00FF")
ai_btn.grid(row=2, column=1, padx=30, pady=15)

# NOW IT'S SAFE ‚Äî buttons exist!
update_temp_and_control()

app.mainloop()

# Cleanup on exit
GPIO.cleanup()